% \chapter{Important first chapter}
% \label{chap:refs}
% 
% First chapter usually builds the theoretical background necessary for readers to understand the rest of the thesis. You should summarize and reference a lot of existing literature and research.
% 
% You should use the standard \emph{citations}\todo{Use \textbackslash{}emph command like this, to highlight the first occurrence of an important word or term. Reader will notice it, and hopefully remember the importance.}.
% 
% \begin{description}
% \item[Obtaining bibTeX citation] Go to Google Scholar\footnote{\url{https://scholar.google.com}}\todo{This footnote is an acceptable way to `cite' webpages or URLs. Documents without proper titles, authors and publishers generally do not form citations. For this reason, avoid citations of wikipedia pages.}, find the relevant literature, click the tiny double-quote button below the link, and copy the bibTeX entry.
% \item[Saving the citation] Insert the bibTeX entry to the file \texttt{refs.bib}. On the first line of the entry you should see the short reference name --- from Scholar, it usually looks like \texttt{author2015title} --- you will use that to refer to the citation.
% \item[Using the citation] Use the \verb|\cite| command to typeset the citation number correctly in the text; a long citation description will be automaticaly added to the bibliography at the end of the thesis. Always use a non-breakable space before the citing parenthesis to avoid unacceptable line breaks:
% \begin{Verbatim}
% Trees utilize gravity to invade ye
% noble sires~\cite{newton1666apple}.
% \end{Verbatim}
% \item[Why should I bother with citations at all?] For two main reasons:
% \begin{itemize}
% \item You do not have to explain everything in the thesis; instead you send the reader to refer to details in some other literature. Use citations to simplify the detailed explanations.
% \item If you describe something that already exists without using a citation, the reviewer may think that you \emph{claim} to have invented it. Expectably, he will demand academic correctness, and, from your perspective, being accused of plagiarism is not a good starting point for a successful defense. Use citations to identify the people who invented the ideas that you build upon.
% \end{itemize}
% \item[How many citations should I use?]
% Cite any non-trivial building block or assumption that you use, if it is published in the literature. You do not have to cite trivia, such as the basic definitions taught in the introductory courses.
% 
% The rule of thumb is that you should read, understand and briefly review at least around 4 scientific papers. A thesis that contains less than 3 sound citations will spark doubt in reviewers.
% \end{description}
% 
% There are several main commands for inserting citations, used as follows:
% \begin{itemize}
% \item \citet{knuth1979tex} described a great system for typesetting theses.
% \item We are typesetting this thesis with \LaTeX, which is based on \TeX{} and METAFONT~\cite{knuth1979tex}.
% \item \TeX{} was expanded to \LaTeX{} by \citet{lamport1994latex}, hence the name.
% \item Revered are the authors of these systems!~\cite{knuth1979tex,lamport1994latex}
% \end{itemize}
% 
% \section{Some extra assorted hints before you start writing English}
% 
% Strictly adhere to the English word order rules. The sentences follow a fixed structure with subject followed by a verb and an object (in this order). Exceptions to this rule must be handled specially, and usually separated by commas.
% 
% Mind the rules for placing commas:
% \begin{itemize}
% \item Use the \emph{Oxford comma} before `and' and `or' at the end of a longer, comma-separated list of items. Certainly use it to disambiguate any possible mixtures of conjunctions: \textit{`The car is available in red, red and green, and green versions.'}
% \item Do not use the comma before subordinate clauses that begin with `that' (like this one). English does not use subordinate clauses as often as Slavic languages because the lack of a suitable word inflection method makes them hard to understand. In scientific English, try to avoid them as much as possible. Ask doubtfully whether each `which' and `when' is necessary --- most of these helper conjunctions can be removed by converting the clause to non-subordinate.
% 
% As an usual example, \xxx{\textit{`The sentence, which I wrote, seemed ugly.'}} is perfectly bad; slightly improved by \xxx{\textit{`The sentence that I wrote seemed ugly.'}}, which can be easily reduced to \textit{`The sentence I wrote seemed ugly.'}. A final version with added storytelling value could say \textit{`I wrote a sentence but it seemed ugly.'}
% \item Consider placing extra commas around any parts of the sentence that break the usual word order, especially if they are longer than a single word.
% \end{itemize}
% 
% Do not write long sentences. One sentence should contain exactly one fact. Multiple facts should be grouped in a paragraph to communicate one coherent idea. Paragraphs are grouped in labeled sections for a sole purpose of making the navigation in the thesis easier. Do not use the headings as `names for paragraphs' --- the text should make perfect sense even if all headings are removed. If a section of your text contains one paragraph per heading, you might have wanted to write an explicit list instead.
% 
% Every noun needs a determiner (`a', `the', `my', `some', \dots); the exceptions to this rule, such as non-adjectivized names and indeterminate plural, are relatively scarce. Without a determiner, a noun can be easily mistaken for something completely different, such as an adjective or a verb.
% 
% Consult the books by \citet{glasman2010science} and \citet{sparling1989english} for more useful details.

\chapter{Theory}

% - LIDAR vs Photogrametrie

\section{Photogrammetry}
Since the Metashape software used by this paper to generate the models is closed-source, there is no easy way to describe the exact algorithms used.
However, a forum statement from the lead developer Dmitry Semyonov \parencite{metashapeForumPost} outlined the general methods used, which this section aims to cover.

The approach to generating models can be summarized as follows:

\begin{enumerate}
	\item \textbf{feature extraction:} for each image, find features that are stable under linear and affine transformations, 3D viewpoint change and illumination
	\item \textbf{feature matching:} match the features across multiple images
	\item \textbf{bundle adjustment:} find the approximate camera locations in space and the position of some of the features in space
	\item \textbf{surface reconstruction:} construct the surface of the model
	\item \textbf{texturing:} apply texture on the constructed model
	\item (optional) \textbf{transformation using markers:} use markers to correctly scale and position the object in the 3D space TODO: this should be done earlier?
\end{enumerate}

The following sections will explore each of these in part.

\subsection{Feature extraction}
The image features are extracted using the Scale Invariant Feature Transform (SIFT) method described in \citet{lowe1999object,lowe2004distinctive,snavely2008modeling}.
Each of the features is a vector, invariant or partially invariant to linear and affine transformations, illuminance change and 3D transformations.
To find such vectors, a Gaussian scale-space is used.

Formally, a scale-space for a given 2D image $I(x, y)$ is defined as a function
$$L(x, y, \sigma) = G(x, y, \sigma) \times I(x, y)$$

The $\times$ symbol is a convolution of the two functions in $x$ and $y$, and $G$ is the Gaussian function
$$G(x, y, \sigma) = \frac{1}{2\pi \sigma^2} e^{-(x^2 + y^2) / 2\sigma^2}$$

This operation is then applied twice on image $I$ with $\sigma = \sqrt{2}$, yielding images $I_{1,1}, I_{2,1}$, the difference of which yields the image $G_1$.
After this, the image $I_{2,1}$ is downscaled by a certain factor (the original method uses $1.5$ with bilinear interpolation) and the process is repeated, yielding $I_{1,2}, I_{2,2}$ and $G_2$, respectively.

To find the features, the local minima and maxima (compared to the 8 neighbouring pixels) of $G_1$ are examined -- if they are also minima/maxima in $G_2$ (accounting for the downscaling), they are chosen as the key points.

The intuitive idea behind this approach is to suppress the finer details of the image, since each of the features in the coarse version of the image should be present in more detail in the original \cite{scalespace}.

To calculate the vectors for each of these key points, the magnitude $M(x,y)$ and orientation $R(x,y)$ is calculated using their neighbouring points via the following formula:
$$
\begin{aligned}
	M(x,y) &= \sqrt{\left(I_{1,1}(x, y) - I_{1,1}(x + 1, y)\right)^2 + \left(I_{1,1}(x,y) - I_{1,1}(x, y + 1)\right)^2} \\[0.7em]
	R(x,y) &= \mathrm{atan2} \left(I_{1,1}(x, y) - I_{1,1}(x + 1, y), I_{1,1}(x,y) - I_{1,1}(x, y + 1)\right)
\end{aligned}
$$

For the vectors to be invariant to orientation and contrast changes, a canonical orientation is calculated from their local image gradients (again using the Gaussian function with some parameter $\sigma$).

TODO: illustration on some images

\subsection{Feature matching}

\subsection{Bundle adjustment}
After the features have been determined and matched across the images, the next step is to simultaneously calculate their position in the 3D space and also the positions of the cameras.
This is referred to as the bundle adjustment problem \cite{schneider19913,snavely2008modeling}, the name referring to bundles of rays from the predicted positions of the points going into the cameras.

Formally, we can model the scene by a vector of $n$ 3D points $\mathbf{X}_i$, taken from $m$ cameras with parameters (position, focal length, etc.) given by the vector $\mathbf{P}_j$.
We have measurements $\underline{\mathbf{x}}_{ij}$ for some of the true features $\mathbf{x}_{ij}$ that are the projections of the $i$-th point on the $j$-th camera.

We then have some model $x()$
% Solving for camera intrinsic and extrinsic orientation parameters.
% PhotoScan uses a greedy algorithm to find approximate camera locations and refines them later using a bundle-adjustment algorithm. This should have many things in common with Bundler, although we didn't compare our algorithm with Bundler thoroughly.
% - https://en.wikipedia.org/wiki/Bundle_adjustment
% - TODO: přečíst stažený papír
% - TODO: že tohle vygeneruje sparse point cloud

\subsection{Surface reconstruction}
% Describe depth map computation
% At this step several processing algorithms are available. Exact, Smooth and Height-field methods are based on pair-wise depth map computation, while Fast method utilizes a multi-view approach.
% - TODO: ?

\subsection{Texturing}
% Texture mapping.
% At this stage PhotoScan parametrizes a surface possibly cutting it in smaller pieces, and then blends source photos to form a texture atlas.
% - TODO: ?
%

\subsection{Transformation using markers}
In certain cases (such as this one), it is necessary for the generated model to be correctly scaled and positioned (in either local or other coordinates) such that it corresponds to its size in the real world.

A common approach uses markers, which are easily recognized and placed around the scanned object.
Since either their pairwise distance or their position is known, it can be used to infer the correct scale of the entire model.

\begin{figure}
\centering
	\includesvg[width=0.7\columnwidth]{images/targets.svg}
	\caption{18th 14-bit marker (left) and the corresponding binary value (right). The grey segments denote the opposing pair of $1$ bits and the blue circle denotes the parity bit.}
\end{figure}

The type of the markers used in Metashape is based on \citet{schneider19913,borisPatent}.
Each circular target contains an inner and outer circle, with the inner serving the purpose of locating the marker in the images and the outer for encoding the marker data.

The exact number of stored bits depends on the size of the marker, most common beind $12$ and $14$ respectively.
The $0$ bits correspond to white segments and $1$ to black ones.
For correctness of decoding the marker data and robustness, the following constraints are additionally imposed on each of the targets:

\begin{itemize}
	\item the targets must be rotationally invariant
	\item the first bit is a parity bit ($0$ for odd, $1$ for even)
	\item there must exist an opposing pair of $1$ bits
\end{itemize}

While this does reduce the number of viable targets (see \cref{tab:markers}), it is still more than enough for the purposes of scanning smaller objects (and thus for the porposes this paper).

\begin{table}
\centering\footnotesize\sf
\begin{tabular}{rrr}
\toprule
Bits & All targets & Valid targets \\
\midrule
12 & 4096   & 147 \\
14 & 16384  & 516 \\
16 & 65536  & 1861 \\
18 & 262144 & 6766 \\
\bottomrule
\end{tabular}
\caption{The number of targets, depending on the desired number of bits \cite{targetsPost}.}
\label{tab:markers}
\end{table}
